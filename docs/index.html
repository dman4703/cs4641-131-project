<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mean Reversion Trader</title>
    <link rel="stylesheet" href="https://latex.now.sh/style.css">
    <style>
        body {
            width: 75% !important;
            max-width: 1250px !important;
        }

        @media (max-width: 768px) {
            body {
                width: 95% !important;
            }
        }

        /* Slideshow Styles */
        .slideshow-container {
            position: relative;
            max-width: 800px;
            margin: 20px auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            overflow: hidden;
        }

        .slide {
            display: none;
            text-align: center;
        }

        .slide.active {
            display: block;
        }

        .slide img {
            width: 100%;
            height: auto;
            display: block;
        }

        .slide-caption {
            padding: 10px;
            background-color: #f8f8f8;
            border-top: 1px solid #ddd;
            font-size: 0.9em;
            color: #333;
        }

        .slideshow-nav {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            background-color: rgba(0, 0, 0, 0.5);
            color: white;
            border: none;
            padding: 10px 15px;
            cursor: pointer;
            font-size: 18px;
            transition: background-color 0.3s;
        }

        .slideshow-nav:hover {
            background-color: rgba(0, 0, 0, 0.8);
        }

        .prev {
            left: 10px;
        }

        .next {
            right: 10px;
        }

        .dots-container {
            text-align: center;
            padding: 10px;
            background-color: #f8f8f8;
        }

        .dot {
            height: 12px;
            width: 12px;
            margin: 0 4px;
            background-color: #bbb;
            border-radius: 50%;
            display: inline-block;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        .dot.active {
            background-color: #333;
        }

        /* Table and Image Styling */
        table {
            margin: 20px auto;
            display: table;
        }

        img {
            display: block;
            margin: 20px auto;
            max-width: 100%;
            height: auto;
        }

        .img-caption {
            text-align: center;
            font-size: 0.9em;
            color: #555;
            font-style: italic;
            margin: -10px auto 20px auto;
            max-width: 800px;
        }
    </style>
</head>
<body>
    <h1>Mean Reversion Trading with Machine Learning</h1>
    <p class="author">
        Devon O'Quinn, Shayali Patel, Nicholas Nitsche, Julien Perez, Mutimu Njenga
    </p>

    <h2><u>Introduction</u></h2>
    <p>Mean reversion trading is based on the principle that prices tend to revert toward their average after 
        periods of overextension. To develop a consistent strategy, we leverage machine learning to make 
        predictions on market data while additionally optimizing performance for low-capital intraday trading.</p>

    <h3>Literature Review</h3>
    <p>
        Key features for mean reversion include VWAP, volume weighted average price, or "the price a 'naive' trader can expect to obtain," and 
        anchored VWAP (AVWAP), which tracks trend direction from a user‑set anchor point [1]. Bollinger Bands 
        provide secondary signals of overbought/oversold conditions through volatility envelopes [2]. The triple 
        barrier method labels trades realistically via profit‑taking, stop‑loss, and time limits [3], while 
        event‑based sampling reduces time‑bar heteroskedasticity [3].
    </p>

    <p>
        Gaussian mixture models can be used to determine probabilistic overextension scores from joint features, 
        and adapt better to regime shifts than z‑scores [4]. Random Forests handle nonlinear, correlated data well [5]; 
        paired with sequential bootstrap, there is less label‑overlap bias [3]. The probabilities output by this model
        indicate position sizes and whether to trade/not trade. Gradient‑boosted trees adapted for quantile 
        regression can be used for exit sizing by predicting conditional quantiles for dynamic stops and targets;
        they outperform classical methods in high‑dimensional settings [6][7].
    </p>

    <p>
        Lastly, model evaluation requires careful consideration. Traditional random test/train splits fail for 
        financial data because features and labels are serially correlated [3]. Purged k‑fold with embargo 
        removes overlap between samples, and combinatorial purged cross-validation (CPCV) returns a distribution of out‑of‑sample metrics from purged 
        k-fold, providing a more reliable measure of model performance [3].
    </p>

    <h3>Dataset Description</h3>
    <p>
        The raw dataset is composed of tick data for 20 liquid U.S. equities, selected from the S&amp;P&nbsp;500 
        using price, liquidity and volatility screens. Data were collected over five trading days (October 2, 3, 6, 7 
        and 8 of 2025) during regular trading hours, excluding the opening and closing five minutes. Each day's file 
        contains millisecond‑timestamped trade prints and quote updates exported from a Bloomberg Terminal. 
        In total the raw universe spans about 21.4 million tick records; after cleaning and consolidation 
        (deduplication, NBBO construction and condition‑code filtering) we have about 1.13 million valid trades 
        across all stocks and days.
    </p>
    <p>
        The 20 selected stocks and their screening statistics are listed below. They cover a broad range of sectors and satisfy our 
        price, liquidity and ATR% criteria. <code>LastClose</code> is the most recent adjusted close price, <code>ADV60d</code> is 
        the mean dollar volume over the previous 60 trading days, and <code>ATRpctMed20</code> is the median 20‑day Average True 
        Range percentage.
    </p>
    <table>
        <caption><strong>Selected Stocks</strong></caption>
        <thead>
            <tr>
                <th>Ticker</th><th>Company</th><th>Sector</th><th>LastClose ($)</th><th>ADV60d ($)</th><th>ATR% (20‑day median)</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>INTC</td><td>Intel</td><td>Information&nbsp;Technology</td><td>37.01</td><td>3.30e9</td><td>4.83</td></tr>
            <tr><td>SMCI</td><td>Supermicro</td><td>Information&nbsp;Technology</td><td>57.69</td><td>1.63e9</td><td>4.13</td></tr>
            <tr><td>TTD</td><td>The Trade Desk</td><td>Communication&nbsp;Services</td><td>53.30</td><td>1.05e9</td><td>4.38</td></tr>
            <tr><td>XYZ</td><td>Block&nbsp;Inc.</td><td>Financials</td><td>80.17</td><td>7.76e8</td><td>3.27</td></tr>
            <tr><td>FCX</td><td>Freeport‑McMoRan</td><td>Materials</td><td>43.15</td><td>7.69e8</td><td>4.67</td></tr>
            <tr><td>CCL</td><td>Carnival</td><td>Consumer&nbsp;Discretionary</td><td>28.70</td><td>5.92e8</td><td>3.07</td></tr>
            <tr><td>MCHP</td><td>Microchip&nbsp;Technology</td><td>Information&nbsp;Technology</td><td>65.64</td><td>5.39e8</td><td>3.09</td></tr>
            <tr><td>KVUE</td><td>Kenvue</td><td>Consumer&nbsp;Staples</td><td>16.53</td><td>4.98e8</td><td>4.39</td></tr>
            <tr><td>CNC</td><td>Centene Corporation</td><td>Health&nbsp;Care</td><td>38.39</td><td>4.76e8</td><td>4.22</td></tr>
            <tr><td>DAL</td><td>Delta Air Lines</td><td>Industrials</td><td>59.70</td><td>4.52e8</td><td>3.00</td></tr>
            <tr><td>ON</td><td>ON Semiconductor</td><td>Information&nbsp;Technology</td><td>50.13</td><td>4.45e8</td><td>3.47</td></tr>
            <tr><td>DLTR</td><td>Dollar Tree</td><td>Consumer&nbsp;Staples</td><td>88.08</td><td>4.34e8</td><td>3.04</td></tr>
            <tr><td>PCG</td><td>PG&amp;E&nbsp;Corp.</td><td>Utilities</td><td>16.53</td><td>3.83e8</td><td>3.41</td></tr>
            <tr><td>DXCM</td><td>Dexcom</td><td>Health&nbsp;Care</td><td>67.80</td><td>3.64e8</td><td>4.58</td></tr>
            <tr><td>DOW</td><td>Dow&nbsp;Inc.</td><td>Materials</td><td>21.94</td><td>3.58e8</td><td>3.74</td></tr>
            <tr><td>NCLH</td><td>Norwegian Cruise Line</td><td>Consumer&nbsp;Discretionary</td><td>23.58</td><td>3.56e8</td><td>3.52</td></tr>
            <tr><td>DECK</td><td>Deckers Brands</td><td>Consumer&nbsp;Discretionary</td><td>99.00</td><td>3.42e8</td><td>3.08</td></tr>
            <tr><td>UBER</td><td>Uber</td><td>Industrials</td><td>98.05</td><td>1.63e9</td><td>2.93</td></tr>
            <tr><td>SLB</td><td>Schlumberger</td><td>Energy</td><td>33.56</td><td>5.62e8</td><td>2.93</td></tr>
            <tr><td>EQT</td><td>EQT Corporation</td><td>Energy</td><td>55.44</td><td>4.47e8</td><td>2.95</td></tr>
        </tbody>
    </table>
    <p>
        After processing, we construct around 600 volume bars per trading day for each ticker, yielding about 46,855 bars with nine 
        derived features and triple‑barrier labels. The cleaning pipeline achieved an average NBBO coverage of 99.99%, 
        zero negative spreads, and an average duplicate removal rate of 33.07%. The final cleaned dataset contains 1,130,327 trades across all 
        tickers and days.
    </p>
    <table>
        <caption><strong>Cleaned Data Schema</strong></caption>
        <thead>
            <tr>
                <th>Column</th><th>Type</th><th>Description</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>ts</td><td>datetime64[ns, UTC]</td><td>Trade timestamp in UTC</td></tr>
            <tr><td>ticker</td><td>object</td><td>Stock ticker symbol</td></tr>
            <tr><td>type</td><td>category</td><td>Event type (TRADE)</td></tr>
            <tr><td>price</td><td>float32</td><td>Trade execution price</td></tr>
            <tr><td>size</td><td>int32</td><td>Trade size in shares</td></tr>
            <tr><td>cond</td><td>object</td><td>Raw trade condition codes</td></tr>
            <tr><td>cond_norm</td><td>object</td><td>Normalized condition codes</td></tr>
            <tr><td>exch</td><td>category</td><td>Exchange identifier</td></tr>
            <tr><td>nbb</td><td>float32</td><td>National best bid price</td></tr>
            <tr><td>nbo</td><td>float32</td><td>National best offer price</td></tr>
            <tr><td>nbb_size</td><td>int32</td><td>National best bid size</td></tr>
            <tr><td>nbo_size</td><td>int32</td><td>National best offer size</td></tr>
            <tr><td>mid</td><td>float32</td><td>Mid-price: 0.5 × (nbb + nbo)</td></tr>
            <tr><td>spread</td><td>float32</td><td>Bid-ask spread: nbo − nbb</td></tr>
            <tr><td>at_bid</td><td>int64</td><td>Flag: trade at bid (1) or not (0)</td></tr>
            <tr><td>at_ask</td><td>int64</td><td>Flag: trade at ask (1) or not (0)</td></tr>
        </tbody>
    </table>


    <h2><u>Problem Definition</u></h2>

    <h3>Problem & Motivation</h3>
    <p>
        Traditional retail day trading strategies utilize naive heuristic rules that result in inconsistent 
        performance; this problem is amplified in low-capital accounts, where limited funds magnify risk and 
        reduce flexibility. We reinterpret the task as a machine learning problem: How can we better 
        distinguish true trading signals from market noise? Instead of doing subjective guesswork, we can 
        engineer event-based features, label outcomes, and train models. This way, we can realize profitable 
        outcomes with reliable, risk-adjusted performance using statistics rather than rule-of-thumb trading.
    </p>

    <h3>Objective</h3>
    <p>
        Given an overextension event where price is far from an AVWAP, determine whether the price will revert 
        sufficiently within the next 15–30 minutes to yield a profitable mean‑reversion trade. If a profitable 
        reversion is likely, determine where to set dynamic take‑profit and stop‑loss levels to maximize 
        returns by predicting the distribution of return magnitudes and executing the trade accordingly.
    </p>

    <h2><u>Methods</u></h2>

    <h3>Data Preprocessing</h3>
    <p>
        <b>Stock Selection.</b> Tickers were drawn from the S&P 500 and filtered for last close between $10 and $100, belonging to 
        the top half of the dollar‑volume distribution, and exhibiting moderate intraday volatility (ATR% between 3% and 5%). 
        When fewer than 20 tickers satisfied these strict criteria we filled the remainder with names closest to the volatility 
        midpoint while still prioritizing liquidity.
    </p>
    <table>
        <caption><strong>Data Cleaning Metrics</strong></caption>
        <thead>
            <tr>
                <th>Metric</th><th>Value</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Raw tick records</td><td>21,419,919</td></tr>
            <tr><td>Final cleaned trades</td><td>1,130,327</td></tr>
            <tr><td>Retention rate</td><td>5.3%</td></tr>
            <tr><td>Avg duplicate removal</td><td>33.07%</td></tr>
            <tr><td>Avg NBBO coverage</td><td>99.99%</td></tr>
            <tr><td>Avg crossed quotes</td><td>0.52%</td></tr>
            <tr><td>Trades dropped (condition codes)</td><td>2,005,302</td></tr>
            <tr><td>Trades dropped (no NBBO)</td><td>140</td></tr>
        </tbody>
    </table>
    <p>
        <b>Cleaning</b>. Bloomberg headers and invalid rows were removed, New York timestamps were parsed to UTC, exact repeats were 
        deduplicated, trades were split from quotes and a National Best Bid and Offer (NBBO) was built by forward‑filling quotes 
        up to 2 seconds. The NBBO construction ensures trades are contextualized against the prevailing market allowing the 
        computation of accurate spreads and assessment of price impact; the 2‑second forward‑fill cap prevents using stale quotes that would 
        misrepresent market conditions. Each trade was merged with the most recent valid NBBO; special condition codes (late reports, 
        auctions, odd lots, extended hours, etc.) were filtered out because these irregular trade types do not reflect normal 
        market liquidity and would introduce bias into our mean‑reversion features. Compressed Parquet files were exported. Quality 
        gates ensured >99% NBBO coverage, zero negative spreads and chronologically ordered timestamps. Average duplicate removal was 
        roughly 33% of raw rows and NBBO crossed quotes occurred in less than 1% of cases.
    </p>
    <p>
        <b>Bar Type</b>. To determine whether to use volume or dollar bars, we performed EDA on three representative tickers. By examining per‑second 
        flow statistics (coefficient of variation, Fano factor, intraday profiles and zero‑activity periods) we found that 
        dollar‑denominated flows were slightly more bursty and less uniform than share‑based flows. Prototype bars built on dollar 
        thresholds also exhibited more variable inter‑bar durations and less white noise in returns. Consequently we adopted volume 
        bars with ticker‑specific thresholds calibrated as median daily volume divided by 600 (clamped between 2,000 and 100,000 shares). 
        This yields approximately 600 bars per day per ticker; each bar captures the OHLC, VWAP, trade count, duration and volume.
    </p>
    <table>
        <caption><strong>Volume Bar Configuration (Selected Tickers)</strong></caption>
        <thead>
            <tr>
                <th>Ticker</th><th>Volume Threshold (shares/bar)</th><th>Target Bars/Day</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>INTC</td><td>20,500</td><td>~600</td></tr>
            <tr><td>PCG</td><td>8,700</td><td>~600</td></tr>
            <tr><td>KVUE</td><td>7,500</td><td>~600</td></tr>
            <tr><td>SMCI</td><td>6,800</td><td>~600</td></tr>
            <tr><td>CCL</td><td>4,600</td><td>~600</td></tr>
            <tr><td>FCX</td><td>4,600</td><td>~600</td></tr>
            <tr><td>TTD</td><td>2,400</td><td>~600</td></tr>
            <tr><td>NCLH</td><td>2,300</td><td>~600</td></tr>
            <tr><td>CNC</td><td>2,200</td><td>~600</td></tr>
            <tr><td>SLB</td><td>2,200</td><td>~600</td></tr>
            <tr><td>DAL</td><td>2,000</td><td>~600</td></tr>
            <tr><td>Others</td><td>2,000</td><td>~600</td></tr>
        </tbody>
    </table>
    <img src="./assets/img/determineBar_8_1.png" alt="Volume vs Dollar bar comparison">
    <p class="img-caption">Figure 1: Comparison of volume vs. dollar bar metrics.</p>
    <p>
        <b>Feature Engineering</b>. From each volume bar we engineered nine features while avoiding look‑ahead bias. These features 
        best capture mean‑reversion signals: VWAP z‑score and Bollinger position directly measure price 
        overextension from mean levels, which is the overarching signal for mean reversion. Three‑ and five‑bar momentum quantify short‑term 
        trend strength that may reverse. Relative volume indicates unusual activity that often precedes reversions. Time of day 
        accounts for intraday liquidity patterns. The three context variables (bar count, 
        average volume, and price range over the past five minutes) provide microstructure information about recent market conditions 
        that affect reversion probability. All rolling statistics are shifted by one bar to ensure the features do not incorporate 
        the current bar's outcome, strictly preventing look‑ahead bias. The feature distributions are approximately symmetric with 
        moderate tails.
    </p>
    <table>
        <caption><strong>Engineered Features</strong></caption>
        <thead>
            <tr>
                <th>Feature</th><th>Description</th><th>Formula / Method</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>VWAP z-score</td><td>Standardized distance from VWAP</td><td>(close − VWAP) / rolling_std(20).shift(1)</td></tr>
            <tr><td>Bollinger position</td><td>Position within Bollinger Bands</td><td>(close − BB_mid) / (BB_upper − BB_mid), 20-bar window, 2σ</td></tr>
            <tr><td>Momentum (3-bar)</td><td>Log return over 3 bars</td><td>log(close / close.shift(3))</td></tr>
            <tr><td>Momentum (5-bar)</td><td>Log return over 5 bars</td><td>log(close / close.shift(5))</td></tr>
            <tr><td>Relative volume</td><td>Volume vs. rolling median</td><td>volume / rolling_median(20).shift(1)</td></tr>
            <tr><td>Time of day</td><td>Normalized time (0=open, 1=close)</td><td>(t − market_open) / market_duration</td></tr>
            <tr><td>Context: bar count</td><td>Number of bars in past 5 minutes</td><td>count(bars where t ≥ current_t − 5min)</td></tr>
            <tr><td>Context: avg volume</td><td>Average volume in past 5 minutes</td><td>mean(volume where t ≥ current_t − 5min)</td></tr>
            <tr><td>Context: price range</td><td>Price range in past 5 minutes</td><td>(max(high) − min(low)) / mean(close)</td></tr>
        </tbody>
    </table>
    <img src="./assets/img/dataEDA_10_0.png" alt="Feature distributions">
    <p class="img-caption">Figure 2: Distribution of the nine engineered features.</p>
    <p>
        <b>Labeling</b>. Labels are derived using the triple‑barrier method with volatility‑scaled price barriers and a 20‑minute time horizon. 
        This approach is preferred over fixed‑price targets or fixed‑time horizons because it adapts to changing volatility regimes 
        and realistically models how traders exit positions—either hitting a profit target, hitting a stop loss, or timing out. We 
        compute an exponentially‑weighted rolling standard deviation of returns (halflife = 50 bars) and set upper and lower 
        barriers at ±1× this volatility from the entry price, ensuring that profit/loss thresholds scale with recent market conditions. 
        A bar receives a label of <code>+1</code> if the upper barrier is hit first, <code>-1</code> if the lower barrier is hit, 
        or <code>0</code> if the time barrier elapses without either price barrier being breached. This reduces path‑dependent 
        labeling bias and produces more realistic training signals than pure forward returns. Across our processed dataset, up and down 
        labels are roughly balanced while neutral events are rare. Holding periods cluster around 30–100 seconds.
    </p>
    <img src="./assets/img/dataEDA_6_0.png" alt="Label distribution">
    <p class="img-caption">Figure 3: Triple-barrier label distribution across a data sample.</p>
    <p>
        <b>Cross-Validation</b>. Finally, we partitioned the data using purged, embargoed cross‑validation. Traditional random splits 
        are inappropriate for financial time‑series because both features and labels exhibit serial correlation: a bar's outcome can 
        influence nearby bars through autocorrelation, shared volatility regimes, and overlapping triple‑barrier windows. In a 
        leave‑one‑day‑out (LODO) scheme, we hold out one trading day for testing and train on the remaining days. We purge any 
        training samples whose entry or exit windows overlap the validation period and enforce a 20‑minute embargo after the validation 
        cut‑off to prevent information leakage. This approach ensures that validation performance reflects 
        out‑of‑sample generalization rather than memorization of temporally adjacent patterns. This yields five folds for the 
        five trading days; in each fold about 7,000–10,000 bars are reserved for validation while the rest form the training set.
    </p>

    <h3>Models</h3>

    <h4>GMM: Unsupervised Overextension Detector</h4>
    <p>
        To identify overextended price moves without supervision, we fit a GMM to the 
        nine‑dimensional feature vectors constructed from the volume bars. We chose an unsupervised approach because labeling 
        "overextension" directly is subjective and would require hindsight bias; instead, we let the model learn the natural 
        distribution of feature patterns and flag anomalies. A GMM models the data as a weighted sum of k 
        components, where each component represents a distinct market regime or pattern in the 
        feature space. We test 8 to 15 components to balance model flexibility against complexity. The GMM assigns each point a 
        probability density: "normal" events receive high probability under the learned distribution, while 
        low‑probability outliers in the tails correspond to unusual, potentially overextended situations worthy of further analysis. 
        We prefer GMMs over simpler alternatives (e.g., univariate z‑scores or Isolation Forest) for several reasons: GMMs 
        capture correlations between features (e.g., VWAP z‑score and Bollinger position often move together), 
        they model multimodality in the feature space, allowing different "normal" regimes to coexist, and 
        they adapt to regime shifts by blending multiple covariance structures rather than assuming a single Gaussian. 
        This provides interpretable anomaly scores and handles the non‑stationary nature of intraday trading data.
    </p>
    <p>
        The model is trained on four of the five trading days (October 2, 3, 6, 7) and tested on the remaining day (October 8). 
        Prior to training we drop rows with missing or infinite feature values (400 training samples, 100 test samples) and standardize 
        each feature in the training set. We tune the number of mixture components 
        (<code>k</code>) and covariance type (<code>full</code> vs. <code>diag</code>) via day‑level LODO cross‑validation on the 
        training data. Model selection follows two steps: first, we identify configurations within one standard deviation 
        of the best cross‑validated log‑likelihood; second, among these candidates we choose the model with the lowest Bayesian Information 
        Criterion (BIC). The selected configuration uses <code>k = 12</code> components with full covariance, achieving a mean cross‑validated 
        log‑likelihood of –7.25 and the lowest BIC (523,136) among models within one standard deviation of the best CV score.
    </p>
    <table>
        <caption><strong>GMM Configuration and Model Selection</strong></caption>
        <thead>
            <tr>
                <th>Parameter</th><th>Value</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Number of components (k)</td><td>12</td></tr>
            <tr><td>Covariance type</td><td>Full</td></tr>
            <tr><td>Training samples</td><td>37,793</td></tr>
            <tr><td>Test samples</td><td>8,562</td></tr>
            <tr><td>Feature dimensionality</td><td>9</td></tr>
            <tr><td>CV mean log-likelihood</td><td>–7.25</td></tr>
            <tr><td>Train AIC</td><td>517,508</td></tr>
            <tr><td>Train BIC</td><td>523,136</td></tr>
            <tr><td>Threshold quantile (primary)</td><td>5th percentile</td></tr>
            <tr><td>Threshold value (5%)</td><td>–14.18</td></tr>
            <tr><td>Threshold value (10%)</td><td>–12.05</td></tr>
        </tbody>
    </table>
    <p>
        After fitting, we compute the per‑sample log‑likelihood under the learned GMM. Events with log‑likelihood below the 
        5th percentile of the training distribution are flagged as overextension candidates. The threshold (–14.18) is chosen 
        purely from the train distribution. For future comparison and sensitivity analysis, we also persist candidates using a 
        10th percentile threshold (–12.05). These flags are not final trading signals; they simply mark the subset of bars that 
        may warrant further analysis by the supervised opportunity classifier. For interpretability we also record the mixture 
        component assignments, which can reveal clusters of feature patterns associated with extremes.
    </p>
    <img src="./assets/img/gmm_15_0.png" alt="GMM model selection">
    <p class="img-caption">Figure 4: GMM model selection via LODO cross-validation showing full covariance models consistently outperform diagonal covariance.</p>

    <h4>Supervised Opportunity Classifier</h4>
    <p>Random Forest trained on the overextension candidates; it outputs the probability of reversion.</p>

    <h4>Supervised Exit Model</h4>
    <p>Gradient‑boosted trees (trained on the events predicted to revert with high probability) to predict τ‑quantiles; we will use 
        the 0.1 quantile as the stop loss condition and the 0.5 quantile as the target condition.</p>

    <h2><u>Results & Discussion</u></h2>

    <h3>GMM: Unsupervised Overextension Detector</h3>
    <p>
        <b>Model Selection and Information Criteria</b>. We evaluated GMM configurations with 8 to 15 components and two covariance types 
        (full and diagonal) using day‑level LODO cross‑validation. Model selection was guided by two constraints: first, we identify models 
        within one standard deviation of the best cross‑validated log‑likelihood; second, among these candidates we select the configuration 
        with the lowest Bayesian Information Criterion (BIC). These metrics are particularly well‑suited for unsupervised GMM evaluation: 
        unlike supervised metrics (accuracy, F1), they do not require ground‑truth labels and instead measure how well the model explains 
        the observed data distribution. This prevents overfitting to validation noise while favoring simpler models 
        when performance is comparable, ensuring the chosen GMM generalizes to new trading days.
    </p>
    <p>
        <b>Log-Likelihood</b>. In an unsupervised setting without ground-truth labels, 
        log‑likelihood is the primary metric for evaluating how well the GMM explains the observed data distribution. It represents the 
        average log‑probability that the fitted GMM assigns to each data point. Higher (less negative) values indicate the model 
        assigns higher probability to the observed feature patterns, meaning it better captures the underlying structure. For example, 
        a mean log‑likelihood of –6.8 is better than –8.0 because the former indicates the model finds the data more probable under its 
        learned distribution. We evaluate log‑likelihood on held‑out validation days to assess generalization: if a model fits the training 
        distribution well but produces lower log‑likelihood on validation data, it has likely overfit. Conversely, similar train and test log‑likelihoods 
        confirm that the model has learned generalizable patterns.
    </p>
    <p>
        Among the 16 configurations evaluated, k=15 full covariance achieved the best CV log‑likelihood (–7.15), but k=12 full covariance was selected due to its 
        substantially lower BIC (523,136) compared to k=15 (530,430), despite a marginal CV difference of only 0.10. AIC (Akaike Information 
        Criterion) and BIC are information‑theoretic metrics that balance goodness‑of‑fit against model 
        complexity; they are ideal for unsupervised GMM selection because they penalize overly complex models that may fit noise rather than 
        signal. BIC applies a stronger penalty than AIC for additional parameters, making it more conservative. Lower AIC and BIC 
        values indicate better models: the 7,000‑point BIC improvement of k=12 over k=15 indicates that three fewer components provide a 
        better parsimony trade‑off—k=15's slight CV advantage does not justify its added complexity. Note that AIC and BIC values 
        scale linearly with sample size (n = 37,793), so absolute magnitudes in the hundreds of thousands are expected; what matters for 
        model comparison is the relative difference between candidates. The diagonal‑covariance models consistently performed worse, 
        suggesting that feature correlations (e.g., between VWAP z-score and Bollinger position) are important for accurately modeling 
        the joint distribution.
    </p>
    <table>
        <caption><strong>GMM Model Selection Results (Top 5 Configurations)</strong></caption>
        <thead>
            <tr>
                <th>k</th><th>Covariance</th><th>CV Mean Log-Lik</th><th>CV Std</th><th>BIC</th><th>AIC</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>15</td><td>full</td><td>–7.15</td><td>0.49</td><td>530,430</td><td>523,393</td></tr>
            <tr><td>12</td><td>full</td><td>–7.25</td><td>0.37</td><td>523,136</td><td>517,508</td></tr>
            <tr><td>13</td><td>full</td><td>–7.26</td><td>0.51</td><td>524,511</td><td>518,414</td></tr>
            <tr><td>11</td><td>full</td><td>–7.30</td><td>0.49</td><td>536,847</td><td>531,689</td></tr>
            <tr><td>14</td><td>full</td><td>–7.31</td><td>0.62</td><td>524,836</td><td>518,269</td></tr>
        </tbody>
    </table>
    <p>
        <b>Generalization and Candidate Flagging</b>. On the fifth (test) day (October 8), the fitted k=12 GMM produced a mean log‑likelihood 
        of –6.86 compared with –6.83 on the training days. These values are nearly identical, confirming that the model generalizes well: 
        it explains the test day's feature distribution about as well as it explains the training data. This similarity suggests that the model 
        has learned patterns that persist across different trading days rather than overfitting. 
        If the test log‑likelihood had been substantially lower (more negative), it would indicate the model failed to capture generalizable structure.
    </p>
    <p>
        Using the 5th percentile threshold (–14.18), about 5.0% of training bars and 5.3% of test bars were 
        flagged as overextension candidates. This stable candidate rate across train and test confirms that the threshold defined on the training 
        distribution transfers reliably to new data. Additionally, we persist a 10th percentile threshold (–12.05) 
        for future sensitivity analysis and comparison with the stricter 5% threshold. The flags represent anomalous feature combinations 
        that fall in the low‑density tails of the learned distribution, marking potential mean‑reversion opportunities for downstream supervised analysis.
    </p>
    <table>
        <caption><strong>GMM Performance</strong></caption>
        <thead>
            <tr>
                <th>Metric</th><th>Train</th><th>Test</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Sample count</td><td>37,793</td><td>8,562</td></tr>
            <tr><td>Mean log-likelihood</td><td>–6.83</td><td>–6.86</td></tr>
            <tr><td>Candidate rate (5%)</td><td>5.00%</td><td>5.34%</td></tr>
            <tr><td>Candidates flagged (5%)</td><td>1,890</td><td>457</td></tr>
        </tbody>
    </table>
    <p>
        A breakdown of flagged vs. unflagged labels shows that both up and down events are represented in 
        roughly equal proportions: in the train set the flagged subset contained 963 positive and 896 negative labels, while the 
        unflagged subset contained 18,099 positive and 17,432 negative labels. Neutral (label 0) events are rare overall (≈1%) and 
        only a handful are flagged.
    </p>
    <table>
        <caption><strong>Label Distribution by Flag Status (Training Set, 5%)</strong></caption>
        <thead>
            <tr>
                <th>Label</th><th>Flagged Count</th><th>Flagged %</th><th>Unflagged Count</th><th>Unflagged %</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Up (+1)</td><td>963</td><td>51.0%</td><td>18,099</td><td>50.5%</td></tr>
            <tr><td>Down (–1)</td><td>896</td><td>47.4%</td><td>17,432</td><td>48.6%</td></tr>
            <tr><td>Neutral (0)</td><td>31</td><td>1.6%</td><td>372</td><td>1.0%</td></tr>
            <tr><td>Total</td><td>1,890</td><td>100%</td><td>35,903</td><td>100%</td></tr>
        </tbody>
    </table>
    <p>
        <b>Interpretability and Feature Space Analysis</b>. The log‑likelihood distributions overlap between train and test and flagged 
        points cluster in low‑density regions when projected into the first two principal components. The flagged bars often correspond 
        to large deviations from VWAP, extreme Bollinger positions, high relative volume or unusual momentum patterns, consistent with 
        our intuition of overextended price moves. However, because the GMM operates on the joint feature space, some moderate deviations 
        can also be flagged if they occur in an atypical feature combination. The model does not assign explicit probabilities to labels; 
        instead, the flags simply identify potential mean‑reversion opportunities for further screening.
    </p>

    <div class="slideshow-container">
        <div class="slide active">
            <img src="./assets/img/gmm_16_5.png" alt="GMM log-likelihood distributions">
            <div class="slide-caption">Figure 5a: Overlapping log-likelihood distributions for train and test sets with 5th percentile threshold marked.</div>
        </div>
        <div class="slide">
            <img src="./assets/img/gmm_16_2.png" alt="GMM candidate rate by ticker">
            <div class="slide-caption">Figure 5b: GMM candidate rate by ticker on test day showing variation across stocks.</div>
        </div>
        <div class="slide">
            <img src="./assets/img/gmm_15_2.png" alt="PCA projection of flagged points">
            <div class="slide-caption">Figure 5c: PCA projection showing flagged candidates (orange) cluster in low-density regions away from normal events (blue).</div>
        </div>
        <div class="slide">
            <img src="./assets/img/gmm_16_6.png" alt="Feature space scatter">
            <div class="slide-caption">Figure 5d: VWAP z-score vs. Bollinger position scatter plot with flagged events.</div>
        </div>
        <button class="slideshow-nav prev" onclick="changeSlide(-1)">&#10094;</button>
        <button class="slideshow-nav next" onclick="changeSlide(1)">&#10095;</button>
        <div class="dots-container">
            <span class="dot active" onclick="currentSlide(0)"></span>
            <span class="dot" onclick="currentSlide(1)"></span>
            <span class="dot" onclick="currentSlide(2)"></span>
            <span class="dot" onclick="currentSlide(3)"></span>
        </div>
    </div>

    <p>
        <b>Next Steps</b>. While the candidate rate of ~5% is a reasonable starting point, several avenues exist to refine the unsupervised detector. 
        First, the feature set could be expanded to include additional context such as order‑book imbalance or realized volatility. 
        Second, alternative density estimators (e.g., Kernel Density Estimation or Normalizing Flows) might capture heavy tails and 
        nonlinear dependencies better than Gaussian mixtures. Third, the threshold could be adaptively set per ticker or per day to 
        account for differing volatility regimes. Despite these limitations, the current GMM provides a principled, interpretable 
        filter that reduces the search space for the supervised models and establishes a baseline for anomaly detection in 
        high‑frequency trading data.
    </p>

    <h3>Supervised Opportunity Classifier</h3>
    <p>TBD. Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix.</p>

    <h3>Supervised Exit Model</h3>
    <p>TBD. Quantile Loss, Pinball Loss, Backtest profit & loss.</p>
    
    <h3>Full Pipeline</h3>
    <p>TBD. Hit Rate, Win/loss ratio, Total profit & loss, Sharpe Ratio. Essentially run a trading simulation with actual entry/exit levels 
        vs. predicted stops/targets.</p>

    <h2><u>Team Logistics</u></h2>

    <h3>Gantt Chart</h3>
    <a href="./assets/img/ganttChartUpdate.png" target="_blank"><img src="./assets/img/ganttChartUpdate.png" alt="Gantt Chart"></a>

    <h3>Contribution Table</h3>
    <table>
        <thead>
            <tr>
                <th>Name</th>
                <th>Midterm Contributions</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Devon O'Quinn</td>
                <td>Data Cleaning, Data Preprocessing, Feature Engineering, Data Visualization, <br>Model Coding & Evaluation, Report Writing (Tables, Plots)</td>
            </tr>
            <tr>
                <td>Shayali Patel</td>
                <td>Report Writing (Model Description Section)</td>
            </tr>
            <tr>
                <td>Nicholas Nitsche</td>
                <td>Report Writing (Results and Discussion Section)</td>
            </tr>
            <tr>
                <td>Julien Perez</td>
                <td>Report Writing (Dataset Description Section)</td>
            </tr>
            <tr>
                <td>Mutimu Njenga</td>
                <td>Report Writing (Data Preprocessing Section)</td>
            </tr>
        </tbody>
    </table>

    <h2><u>References</u></h2>
    <p>[1] B. Shannon, "Anchored VWAP," <em>Alphatrends</em>. [Online]. Available: <a href="https://alphatrends.net/anchored-vwap/" target="_blank">https://alphatrends.net/anchored-vwap/</a></p>

    <p>[2] C. Thompson, "Understanding Bollinger Bands: A Key Technical Analysis Tool for Investors," <em>Investopedia</em>, Sep. 3, 2025. [Online]. Available: <a href="https://www.investopedia.com/terms/b/bollingerbands.asp" target="_blank">https://www.investopedia.com/terms/b/bollingerbands.asp</a></p>

    <p>[3] M. López de Prado, <em>Advances in Financial Machine Learning</em>. Wiley, 2018.</p>

    <p>[4] C. M. Bishop, <em>Pattern Recognition and Machine Learning</em>. New York, NY: Springer, 2006, ch. 9.</p>

    <p>[5] L. Breiman, "Random Forests," <em>Machine Learning</em>, vol. 45, no. 1, pp. 5–32, 2001. DOI: 10.1023/A:1010933404324</p>

    <p>[6] J. H. Friedman, "Greedy Function Approximation: A Gradient Boosting Machine," <em>Annals of Statistics</em>, vol. 29, no. 5, pp. 1189–1232, 2001. DOI: 10.1214/aos/1013203451</p>

    <p>[7] N. Meinshausen, "Quantile Regression Forests," <em>Journal of Machine Learning Research</em>, vol. 7, pp. 983–999, 2006.</p>

    <script>
        let currentSlideIndex = 0;

        function changeSlide(direction) {
            const slides = document.querySelectorAll('.slide');
            const dots = document.querySelectorAll('.dot');
            slides[currentSlideIndex].classList.remove('active');
            dots[currentSlideIndex].classList.remove('active');
            currentSlideIndex = (currentSlideIndex + direction + slides.length) % slides.length;
            slides[currentSlideIndex].classList.add('active');
            dots[currentSlideIndex].classList.add('active');
        }

        function currentSlide(index) {
            const slides = document.querySelectorAll('.slide');
            const dots = document.querySelectorAll('.dot');
            slides[currentSlideIndex].classList.remove('active');
            dots[currentSlideIndex].classList.remove('active');
            currentSlideIndex = index;
            slides[currentSlideIndex].classList.add('active');
            dots[currentSlideIndex].classList.add('active');
        }
    </script>
</body>
</html>

